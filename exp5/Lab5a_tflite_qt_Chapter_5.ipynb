{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BLhm2wQXxfh3"
   },
   "source": [
    "# Book: Hands on TinyML\n",
    " Chapter 05-01\n",
    "## TensorFlow Lite with mnist-fashion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "MeQJVE8ooSWm"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import random\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dropout, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WALjcEd_YY_Z"
   },
   "source": [
    "Load Fashion_MNIST database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CFWueErRpUiM",
    "outputId": "17d279e9-db31-40fc-ec17-413beea4647c"
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cN_n53vMYfHj"
   },
   "source": [
    "Plot random image samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 507
    },
    "id": "mBaXULHhpvb0",
    "outputId": "1462bb46-3d91-4d66-f938-622cf207302a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams['figure.figsize'] = (5,5)\n",
    "\n",
    "for i in range(9):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    num = random.randint(0, len(X_train))\n",
    "    plt.imshow(X_train[num], cmap='gray')\n",
    "    plt.title(\"Class {}\".format(y_train[num]))\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "04atR1TVYoTV"
   },
   "source": [
    "Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "STRQvzEkrfV_"
   },
   "outputs": [],
   "source": [
    "num_class = 10\n",
    "X_train = X_train.astype('float32')   # change integers to 32-bit floating point numbers\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "X_train /= 255                        # normalize the input\n",
    "X_test /= 255\n",
    "\n",
    "X_train = X_train.reshape(-1, X_train.shape[1], X_train.shape[2], 1)\n",
    "X_test = X_test.reshape(-1, X_test.shape[1], X_test.shape[2], 1)\n",
    "\n",
    "y_train = to_categorical(y_train, num_class)\n",
    "y_test = to_categorical(y_test, num_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7DUqfU2qYuOf"
   },
   "source": [
    "Model definition the baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "sgCdrSnRszlB"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cacc/miniconda3/envs/ml/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()      \n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation=\"relu\", input_shape = (28,28,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(100, activation = \"relu\"))\n",
    "model.add(Dense(num_class, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wwZxr5nvtaSn",
    "outputId": "4e74e0d3-0e3b-4d2f-b0ef-268d6548c412"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">160,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,010</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │       \u001b[38;5;34m160,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,010\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">179,926</span> (702.84 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m179,926\u001b[0m (702.84 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">179,926</span> (702.84 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m179,926\u001b[0m (702.84 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "12Y68hEWYy4_"
   },
   "source": [
    "Configure and train the baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jPSnyuOrt1QE",
    "outputId": "fb14dbc4-e79f-4669-b088-4dded8a3b108"
   },
   "outputs": [],
   "source": [
    "opt = Adam(0.002)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer = opt, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3S4KcVpcuVYy",
    "outputId": "5f25223b-95e7-4c68-af7d-675b79a856b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m458/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7270 - loss: 0.7585"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-29 19:10:07.867927: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_647', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.7990 - loss: 0.5499\n",
      "Epoch 2/15\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8616 - loss: 0.3777\n",
      "Epoch 3/15\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8759 - loss: 0.3347\n",
      "Epoch 4/15\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8884 - loss: 0.3046\n",
      "Epoch 5/15\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8935 - loss: 0.2875\n",
      "Epoch 6/15\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8985 - loss: 0.2677\n",
      "Epoch 7/15\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9038 - loss: 0.2586\n",
      "Epoch 8/15\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9076 - loss: 0.2440\n",
      "Epoch 9/15\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9101 - loss: 0.2363\n",
      "Epoch 10/15\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9151 - loss: 0.2281\n",
      "Epoch 11/15\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9154 - loss: 0.2234\n",
      "Epoch 12/15\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9179 - loss: 0.2160\n",
      "Epoch 13/15\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9224 - loss: 0.2070\n",
      "Epoch 14/15\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9200 - loss: 0.2069\n",
      "Epoch 15/15\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9255 - loss: 0.1967\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7a0adb1d66b0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=128, epochs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5zMeHSMnchvO"
   },
   "source": [
    "Evaluate on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "URZ4VVGTwTGe",
    "outputId": "292951b2-538a-43ee-9b26-44b0bfdea34f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9130 - loss: 0.2414\n",
      "accuracy on test data: 0.9129999876022339\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test)\n",
    "print('accuracy on test data:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "REqMMbtZcnsX"
   },
   "source": [
    "Save the TF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "nqFtkgMA56K2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('baseline_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bgiAr19nckOX"
   },
   "source": [
    "Load the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "zIvT2kKl6yVH"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "baseline_model = load_model('baseline_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NAKwIc_sctBk"
   },
   "source": [
    "Convert it into an Equivalent TFLite model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z5dl7ufH7xMw",
    "outputId": "1338affd-280d-49cd-d7b9-eebfa7286c3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpztplfpsc/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpztplfpsc/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmpztplfpsc'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='input_layer_1')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 10), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  134187043673664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  134187054037328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  134187054033808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  134187053416144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  134187053401184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  134187053320672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  134187053320496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  134187053322432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1759144224.284660   10264 tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "W0000 00:00:1759144224.284676   10264 tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2025-09-29 19:10:24.284780: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpztplfpsc\n",
      "2025-09-29 19:10:24.285123: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2025-09-29 19:10:24.285127: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /tmp/tmpztplfpsc\n",
      "2025-09-29 19:10:24.287579: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2025-09-29 19:10:24.306713: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /tmp/tmpztplfpsc\n",
      "2025-09-29 19:10:24.311995: I tensorflow/cc/saved_model/loader.cc:471] SavedModel load for tags { serve }; Status: success: OK. Took 27217 microseconds.\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(baseline_model)\n",
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2fkqFvhDc8Kc"
   },
   "source": [
    "Save the TFLite model in your workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E0z_e1f78leK",
    "outputId": "0bff672c-dd9b-43e7-ffdb-4f677554c392"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "723844"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pathlib\n",
    "\n",
    "tflite_models_dir = pathlib.Path(\"./tflite_models/\")\n",
    "tflite_models_dir.mkdir(exist_ok=True, parents=True)\n",
    "tflite_model_file = tflite_models_dir/\"model.tflite\"\n",
    "tflite_model_file.write_bytes(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dlh6ENPec0Qm"
   },
   "source": [
    "You can also export a TensorFlow model as a concrete function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7lQ1CCQt-W8G",
    "outputId": "2da7a570-5176-4013-b953-4811bfcfd608"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Please consider providing the trackable_obj argument in the from_concrete_functions. Providing without the trackable_obj argument is deprecated and it will use the deprecated conversion path.\n",
      "I0000 00:00:1759144224.421954   10264 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "I0000 00:00:1759144224.422103   10264 single_machine.cc:376] Starting new session\n",
      "I0000 00:00:1759144224.422861   10264 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6291 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "W0000 00:00:1759144224.460053   10264 tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "W0000 00:00:1759144224.460072   10264 tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n"
     ]
    }
   ],
   "source": [
    "# export model as  a concrete function\n",
    "func = tf.function(baseline_model).get_concrete_function(\n",
    "    tf.TensorSpec(baseline_model.inputs[0].shape, baseline_model.inputs[0].dtype))\n",
    "# serialized graph representation of the concrte function\n",
    "func.graph.as_graph_def()\n",
    "# converting the concrete function to TfLite \n",
    "converter =  tf.lite.TFLiteConverter.from_concrete_functions([func])\n",
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VV9do-cQn11J"
   },
   "source": [
    "Prediction on the test set using the TFLite model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6T_zQPXA-veG",
    "outputId": "1fcdbcd7-8c13-40cd-aa95-5eb42675a5a9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cacc/miniconda3/envs/ml/lib/python3.10/site-packages/tensorflow/lite/python/interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
      "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
      "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
      "    for details.\n",
      "    \n",
      "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy =  0.913\n"
     ]
    }
   ],
   "source": [
    "tflite_model_file = 'tflite_models/model.tflite'          \n",
    "interpreter = tf.lite.Interpreter(model_path=tflite_model_file)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "\n",
    "pred_list = []\n",
    "for images in X_test:\n",
    "  input_data = np.array(images, dtype=np.float32)\n",
    "\n",
    "  input_data = input_data.reshape(1, input_data.shape[0], input_data.shape[1], 1)\n",
    "\n",
    "  interpreter.set_tensor(input_index, input_data)\n",
    "  interpreter.invoke()\n",
    "  prediction = interpreter.get_tensor(output_index)\n",
    "  prediction = np.argmax(prediction)\n",
    "  pred_list.append(prediction)\n",
    "\n",
    "accurate_count = 0\n",
    "for index in range(len(pred_list)):\n",
    "  if pred_list[index] == np.argmax(y_test[index]):\n",
    "      accurate_count += 1\n",
    "accuracy = accurate_count * 1.0 / len(pred_list)\n",
    "\n",
    "print('accuracy = ', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iejobVRd4ebx"
   },
   "source": [
    "Post training quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FN4Iij_xKwO5",
    "outputId": "c35b4b51-e998-4627-afd7-ccf311bf9dcd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp8yqslok7/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp8yqslok7/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmp8yqslok7'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='input_layer_1')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 10), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  134187043673664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  134187054037328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  134187054033808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  134187053416144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  134187053401184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  134187053320672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  134187053320496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  134187053322432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1759144225.286422   10264 tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "W0000 00:00:1759144225.286440   10264 tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2025-09-29 19:10:25.286566: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmp8yqslok7\n",
      "2025-09-29 19:10:25.287011: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2025-09-29 19:10:25.287016: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /tmp/tmp8yqslok7\n",
      "2025-09-29 19:10:25.290251: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2025-09-29 19:10:25.307768: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /tmp/tmp8yqslok7\n",
      "2025-09-29 19:10:25.312700: I tensorflow/cc/saved_model/loader.cc:471] SavedModel load for tags { serve }; Status: success: OK. Took 26136 microseconds.\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(baseline_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_model_ptq = converter.convert()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xYdYHLbL4hUk"
   },
   "source": [
    "Save the model after post-training quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6H7v-71JK9zm",
    "outputId": "4bd16669-bf33-448e-cc58-41934570c011"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190440"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tflite_models_dir = pathlib.Path(\"./tflite_models/\")\n",
    "tflite_models_dir.mkdir(exist_ok=True, parents=True)\n",
    "tflite_model_file = tflite_models_dir/\"model_ptq.tflite\"\n",
    "tflite_model_file.write_bytes(tflite_model_ptq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QCr73kuo4vHS"
   },
   "source": [
    "Evaluate the model performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BgoX_k52LKh2",
    "outputId": "de0df327-6be5-45e3-c51c-a0f5c0d8365f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cacc/miniconda3/envs/ml/lib/python3.10/site-packages/tensorflow/lite/python/interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
      "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
      "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
      "    for details.\n",
      "    \n",
      "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9128\n"
     ]
    }
   ],
   "source": [
    "tflite_model_file = 'tflite_models/model_ptq.tflite'          \n",
    "interpreter = tf.lite.Interpreter(model_path=tflite_model_file)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "\n",
    "pred_list = []\n",
    "for images in X_test:\n",
    "  input_data = np.array(images, dtype=np.float32)\n",
    "\n",
    "  input_data = input_data.reshape(1, input_data.shape[0], input_data.shape[1], 1)\n",
    "\n",
    "  interpreter.set_tensor(input_index, input_data)\n",
    "  interpreter.invoke()\n",
    "  prediction = interpreter.get_tensor(output_index)\n",
    "  prediction = np.argmax(prediction)\n",
    "  pred_list.append(prediction)\n",
    "\n",
    "accurate_count = 0\n",
    "for index in range(len(pred_list)):\n",
    "  if pred_list[index] == np.argmax(y_test[index]):\n",
    "      accurate_count += 1\n",
    "accuracy = accurate_count * 1.0 / len(pred_list)\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k-hY69aM4ww5"
   },
   "source": [
    "Install the package for TensorFlow Model Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SZv30jfeRv-G",
    "outputId": "e9d88dc7-5aa3-4d4b-ed4b-7bf266d588e6"
   },
   "outputs": [],
   "source": [
    " !pip install -q tensorflow-model-optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1nFxNJth414q"
   },
   "source": [
    "Quantization aware training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VH2X9H2SRkCh",
    "outputId": "d7e0f00f-2f29-4fa8-c90d-a78698ccf089"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "`to_quantize` can only either be a keras Sequential or Functional model.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Use the updated API\u001b[39;00m\n\u001b[1;32m      8\u001b[0m quantize_model \u001b[38;5;241m=\u001b[39m tfmot\u001b[38;5;241m.\u001b[39mquantization\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mquantize_model\n\u001b[0;32m---> 10\u001b[0m q_aware_model \u001b[38;5;241m=\u001b[39m \u001b[43mquantize_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbaseline_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Re-compile\u001b[39;00m\n\u001b[1;32m     13\u001b[0m q_aware_model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m     14\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     15\u001b[0m     loss\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mCategoricalCrossentropy(from_logits\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m     16\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     17\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.10/site-packages/tensorflow_model_optimization/python/core/quantization/keras/quantize.py:135\u001b[0m, in \u001b[0;36mquantize_model\u001b[0;34m(to_quantize, quantized_layer_name_prefix)\u001b[0m\n\u001b[1;32m    129\u001b[0m   quantized_layer_name_prefix \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(to_quantize, keras\u001b[38;5;241m.\u001b[39mSequential) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28mhasattr\u001b[39m(to_quantize, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_is_graph_network\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m to_quantize\u001b[38;5;241m.\u001b[39m_is_graph_network\n\u001b[1;32m    134\u001b[0m ):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m--> 135\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    136\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`to_quantize` can only either be a keras Sequential or \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    137\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFunctional model.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    138\u001b[0m   )\n\u001b[1;32m    140\u001b[0m annotated_model \u001b[38;5;241m=\u001b[39m quantize_annotate_model(to_quantize)\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m quantize_apply(\n\u001b[1;32m    142\u001b[0m     annotated_model, quantized_layer_name_prefix\u001b[38;5;241m=\u001b[39mquantized_layer_name_prefix)\n",
      "\u001b[0;31mValueError\u001b[0m: `to_quantize` can only either be a keras Sequential or Functional model."
     ]
    }
   ],
   "source": [
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "baseline_model = load_model('baseline_model.h5')\n",
    "\n",
    "quantized_model = tfmot.quantization.keras.quantize_model\n",
    "\n",
    "# q_aware stands for for quantization aware.\n",
    "q_aware_model = quantized_model(baseline_model)\n",
    "\n",
    "# `quantize_model` requires a recompile.\n",
    "q_aware_model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "q_aware_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nR-f4VcE5A7L"
   },
   "source": [
    "Require a retraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d-U2p0WuR1PX",
    "outputId": "3abf720c-8681-44d2-b523-2da44aaa9b4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/keras/src/backend.py:5562: UserWarning: \"`categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/108 [==============================] - 10s 80ms/step - loss: 0.1949 - accuracy: 0.9276 - val_loss: 0.1506 - val_accuracy: 0.9433\n",
      "Epoch 2/2\n",
      "108/108 [==============================] - 8s 76ms/step - loss: 0.1811 - accuracy: 0.9323 - val_loss: 0.1479 - val_accuracy: 0.9443\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f7145e55af0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_aware_model.fit(X_train, y_train,\n",
    "                  batch_size=500, epochs=2, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jDg6FduM46S5"
   },
   "source": [
    "Convert and save the model as a TFLite file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ysjav1fQSuGJ",
    "outputId": "8c016ec7-29f3-4c68-8d54-b94d6719f761"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpf5_vbtxo/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpf5_vbtxo/assets\n",
      "/usr/local/lib/python3.9/dist-packages/tensorflow/lite/python/convert.py:887: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n",
      "2025-08-24 07:33:26.645506: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2025-08-24 07:33:26.645543: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2025-08-24 07:33:26.645823: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/tmpf5_vbtxo\n",
      "2025-08-24 07:33:26.649420: I tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
      "2025-08-24 07:33:26.649447: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /tmp/tmpf5_vbtxo\n",
      "2025-08-24 07:33:26.662267: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2025-08-24 07:33:26.768103: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /tmp/tmpf5_vbtxo\n",
      "2025-08-24 07:33:26.799633: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 153810 microseconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "187792"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(q_aware_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_model_qat = converter.convert()\n",
    "\n",
    "tflite_models_dir = pathlib.Path(\"./tflite_models/\")\n",
    "tflite_models_dir.mkdir(exist_ok=True, parents=True)\n",
    "tflite_model_file = tflite_models_dir/\"model_qat.tflite\"\n",
    "tflite_model_file.write_bytes(tflite_model_qat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Nv2byVT6_AS"
   },
   "source": [
    "Evalaute on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tofFGt6XTJAQ",
    "outputId": "ef3b6aa4-1f51-480f-eb2d-53acdc00959c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy =  0.9215\n"
     ]
    }
   ],
   "source": [
    "tflite_model_file = 'tflite_models/model_qat.tflite'          \n",
    "interpreter = tf.lite.Interpreter(model_path=tflite_model_file)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "\n",
    "pred_list = []\n",
    "for images in X_test:\n",
    "  input_data = np.array(images, dtype=np.float32)\n",
    "\n",
    "  input_data = input_data.reshape(1, input_data.shape[0], input_data.shape[1], 1)\n",
    "\n",
    "  interpreter.set_tensor(input_index, input_data)\n",
    "  interpreter.invoke()\n",
    "  prediction = interpreter.get_tensor(output_index)\n",
    "  prediction = np.argmax(prediction)\n",
    "  pred_list.append(prediction)\n",
    "\n",
    "accurate_count = 0\n",
    "for index in range(len(pred_list)):\n",
    "  if pred_list[index] == np.argmax(y_test[index]):\n",
    "      accurate_count += 1\n",
    "accuracy = accurate_count * 1.0 / len(pred_list)\n",
    "\n",
    "print('accuracy = ', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vf9lKxKx7CPQ"
   },
   "source": [
    "Selective quantization only on dense layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JqxoiXZRVIot",
    "outputId": "4c51d4bb-4e61-4c45-c144-14574ab50c5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 13, 13, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 5, 5, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1600)              0         \n",
      "                                                                 \n",
      " quant_dropout (QuantizeWra  (None, 1600)              1         \n",
      " pperV2)                                                         \n",
      "                                                                 \n",
      " quant_dense (QuantizeWrapp  (None, 100)               160105    \n",
      " erV2)                                                           \n",
      "                                                                 \n",
      " quant_dense_1 (QuantizeWra  (None, 10)                1015      \n",
      " pperV2)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 179937 (702.88 KB)\n",
      "Trainable params: 179926 (702.84 KB)\n",
      "Non-trainable params: 11 (44.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "baseline_model = load_model('baseline_model.h5')\n",
    "\n",
    "def apply_quantization(layer):\n",
    "      if isinstance(layer, tf.keras.layers.Dense):\n",
    "        return tfmot.quantization.keras.quantize_annotate_layer(layer)\n",
    "      return layer\n",
    "annotated_model = tf.keras.models.clone_model(baseline_model,clone_function=apply_quantization,)\n",
    "q_aware_model_dense = tfmot.quantization.keras.quantize_apply(annotated_model)\n",
    "q_aware_model_dense.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ukTOb5YIVcv_",
    "outputId": "b9b37fc8-2886-45ac-e414-f5de42311fcd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/keras/src/backend.py:5562: UserWarning: \"`categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/108 [==============================] - 7s 54ms/step - loss: 0.1898 - accuracy: 0.9306 - val_loss: 0.1465 - val_accuracy: 0.9465\n",
      "Epoch 2/2\n",
      "108/108 [==============================] - 6s 52ms/step - loss: 0.1765 - accuracy: 0.9338 - val_loss: 0.1475 - val_accuracy: 0.9455\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f72807492e0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_aware_model_dense.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "q_aware_model_dense.fit(X_train, y_train,\n",
    "                  batch_size=500, epochs=2, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y4H6IWhW9Kn7"
   },
   "source": [
    "Weight pruning based optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6RKkPPvk9PmI"
   },
   "outputs": [],
   "source": [
    "baseline_model = load_model('baseline_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qvsE9j1l-S-W"
   },
   "source": [
    "Apply a pruning scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dKo-cxEWwjF4",
    "outputId": "69c92c85-71bb-4706-f189-5350715454ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " prune_low_magnitude_conv2d  (None, 26, 26, 32)        610       \n",
      "  (PruneLowMagnitude)                                            \n",
      "                                                                 \n",
      " prune_low_magnitude_max_po  (None, 13, 13, 32)        1         \n",
      " oling2d (PruneLowMagnitude                                      \n",
      " )                                                               \n",
      "                                                                 \n",
      " prune_low_magnitude_conv2d  (None, 11, 11, 64)        36930     \n",
      " _1 (PruneLowMagnitude)                                          \n",
      "                                                                 \n",
      " prune_low_magnitude_max_po  (None, 5, 5, 64)          1         \n",
      " oling2d_1 (PruneLowMagnitu                                      \n",
      " de)                                                             \n",
      "                                                                 \n",
      " prune_low_magnitude_flatte  (None, 1600)              1         \n",
      " n (PruneLowMagnitude)                                           \n",
      "                                                                 \n",
      " prune_low_magnitude_dropou  (None, 1600)              1         \n",
      " t (PruneLowMagnitude)                                           \n",
      "                                                                 \n",
      " prune_low_magnitude_dense   (None, 100)               320102    \n",
      " (PruneLowMagnitude)                                             \n",
      "                                                                 \n",
      " prune_low_magnitude_dense_  (None, 10)                2012      \n",
      " 1 (PruneLowMagnitude)                                           \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 359658 (1.37 MB)\n",
      "Trainable params: 179926 (702.84 KB)\n",
      "Non-trainable params: 179732 (702.11 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 2\n",
    "validation_split = 0.1 # 10% of training set will be used for validation set. \n",
    "\n",
    "num_samples = X_train.shape[0] * (1 - validation_split)\n",
    "end_step = np.ceil(num_samples / batch_size).astype(np.int32) * epochs\n",
    "\n",
    "# Define model for pruning.\n",
    "pruning_params = {\n",
    "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.40,\n",
    "                                                               final_sparsity=0.75,\n",
    "                                                               begin_step=0,\n",
    "                                                               end_step=end_step)\n",
    "}\n",
    "\n",
    "model_for_pruning = prune_low_magnitude(baseline_model, **pruning_params)\n",
    "\n",
    "# `prune_low_magnitude` requires a recompile.\n",
    "model_for_pruning.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_for_pruning.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WTH-RUP5-XeD"
   },
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DWWnzUEd1rWU",
    "outputId": "59464dd2-3fc1-46d9-b9a3-886cb02233d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "422/422 [==============================] - 11s 18ms/step - loss: 0.2685 - accuracy: 0.8989 - val_loss: 0.2596 - val_accuracy: 0.9008\n",
      "Epoch 2/2\n",
      "422/422 [==============================] - 7s 17ms/step - loss: 0.2794 - accuracy: 0.8958 - val_loss: 0.2401 - val_accuracy: 0.9090\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f726e14f5e0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tempfile\n",
    "\n",
    "\n",
    "log_dir = tempfile.mkdtemp()\n",
    "callbacks = [\n",
    "    tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "    tfmot.sparsity.keras.PruningSummaries(log_dir=log_dir)\n",
    "]\n",
    "\n",
    "model_for_pruning.fit(X_train, y_train,\n",
    "                  batch_size=batch_size, epochs=epochs, validation_split=validation_split,\n",
    "                  callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z99zMUDT_JDv"
   },
   "source": [
    "Export and save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wpEYHP-08-Bl",
    "outputId": "9fb69dd0-3350-49a0-fd64-d6e3404eb2b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmprmq_a0mf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmprmq_a0mf/assets\n",
      "2025-08-24 07:39:56.613375: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2025-08-24 07:39:56.613410: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2025-08-24 07:39:56.613636: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/tmprmq_a0mf\n",
      "2025-08-24 07:39:56.614789: I tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
      "2025-08-24 07:39:56.614818: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /tmp/tmprmq_a0mf\n",
      "2025-08-24 07:39:56.617567: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2025-08-24 07:39:56.642037: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /tmp/tmprmq_a0mf\n",
      "2025-08-24 07:39:56.651589: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 37954 microseconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "723104"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
    "tflite_model_pruned = converter.convert()\n",
    "\n",
    "import pathlib\n",
    "tflite_models_dir = pathlib.Path(\"./tflite_models/\")\n",
    "tflite_models_dir.mkdir(exist_ok=True, parents=True)\n",
    "tflite_model_file = tflite_models_dir/\"model_pruned.tflite\"\n",
    "tflite_model_file.write_bytes(tflite_model_pruned)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jUT2NFpUKjME"
   },
   "source": [
    "Evaluate on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CDF_AvIc9pes",
    "outputId": "9867e526-5739-4f30-cd48-23816157f662"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8961\n"
     ]
    }
   ],
   "source": [
    "tflite_model_file = 'tflite_models/model_pruned.tflite'          \n",
    "interpreter = tf.lite.Interpreter(model_path=tflite_model_file)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "\n",
    "pred_list = []\n",
    "for images in X_test:\n",
    "  input_data = np.array(images, dtype=np.float32)\n",
    "\n",
    "  input_data = input_data.reshape(1, input_data.shape[0], input_data.shape[1], 1)\n",
    "\n",
    "  interpreter.set_tensor(input_index, input_data)\n",
    "  interpreter.invoke()\n",
    "  prediction = interpreter.get_tensor(output_index)\n",
    "  prediction = np.argmax(prediction)\n",
    "  pred_list.append(prediction)\n",
    "\n",
    "accurate_count = 0\n",
    "for index in range(len(pred_list)):\n",
    "  if pred_list[index] == np.argmax(y_test[index]):\n",
    "      accurate_count += 1\n",
    "accuracy = accurate_count * 1.0 / len(pred_list)\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hX16UIYuKmk5"
   },
   "source": [
    "Save model file in a compressed zip format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IXqWJ6Qm-ABD",
    "outputId": "fe35a5cc-70b6-41f3-ce43-ae680ed574e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of compresssed baseline model: 670789.00 bytes\n",
      "Size of zipped pruned TFlite model: 245796.00 bytes\n"
     ]
    }
   ],
   "source": [
    "def get_gzipped_model(file):\n",
    "  import os\n",
    "  import zipfile\n",
    "  import tempfile\n",
    "\n",
    "  _, zipped_file = tempfile.mkstemp('.zip')\n",
    "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "    f.write(file)\n",
    "\n",
    "  return os.path.getsize(zipped_file)\n",
    "\n",
    "print(\"Size of compresssed baseline model: %.2f bytes\" % (get_gzipped_model('tflite_models/model.tflite')))\n",
    "\n",
    "print(\"Size of zipped pruned TFlite model: %.2f bytes\" % (get_gzipped_model('tflite_models/model_pruned.tflite')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_6Md4_bLKqxE"
   },
   "source": [
    "Selective pruning only to the dense layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bZwMs7-sOo6_",
    "outputId": "e8d143f4-68f0-4d6e-8d26-28f3ab06036a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 13, 13, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 5, 5, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1600)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1600)              0         \n",
      "                                                                 \n",
      " prune_low_magnitude_dense   (None, 100)               320102    \n",
      " (PruneLowMagnitude)                                             \n",
      "                                                                 \n",
      " prune_low_magnitude_dense_  (None, 10)                2012      \n",
      " 1 (PruneLowMagnitude)                                           \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 340930 (1.30 MB)\n",
      "Trainable params: 179926 (702.84 KB)\n",
      "Non-trainable params: 161004 (628.93 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "baseline_model = load_model('baseline_model.h5')\n",
    "def apply_pruning(layer):\n",
    "  if isinstance(layer, tf.keras.layers.Dense):\n",
    "    return tfmot.sparsity.keras.prune_low_magnitude(layer)\n",
    "  return layer\n",
    "\n",
    "model_for_pruning = tf.keras.models.clone_model(\n",
    "    baseline_model,\n",
    "    clone_function=apply_pruning)\n",
    "\n",
    "model_for_pruning.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vMm3d3GgWzIE",
    "outputId": "cae43642-523c-4e93-c3e0-99e032943de1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/keras/src/backend.py:5562: UserWarning: \"`categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "422/422 [==============================] - 9s 17ms/step - loss: 0.2000 - accuracy: 0.9248 - val_loss: 0.1559 - val_accuracy: 0.9412\n",
      "Epoch 2/2\n",
      "422/422 [==============================] - 7s 17ms/step - loss: 0.1910 - accuracy: 0.9278 - val_loss: 0.1611 - val_accuracy: 0.9380\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f7280ad8520>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_for_pruning.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "log_dir = tempfile.mkdtemp()\n",
    "callbacks = [\n",
    "    tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "    tfmot.sparsity.keras.PruningSummaries(log_dir=log_dir)\n",
    "]\n",
    "\n",
    "model_for_pruning.fit(X_train, y_train,\n",
    "                  batch_size=batch_size, epochs=epochs, validation_split=validation_split,\n",
    "                  callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fwgQGf09Xf9I",
    "outputId": "134704b6-3312-4f42-8859-878b566942ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpdo99qwpr/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpdo99qwpr/assets\n",
      "2025-08-24 07:40:36.922505: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2025-08-24 07:40:36.922542: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2025-08-24 07:40:36.922791: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/tmpdo99qwpr\n",
      "2025-08-24 07:40:36.924038: I tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
      "2025-08-24 07:40:36.924062: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /tmp/tmpdo99qwpr\n",
      "2025-08-24 07:40:36.927050: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2025-08-24 07:40:36.952173: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /tmp/tmpdo99qwpr\n",
      "2025-08-24 07:40:36.962136: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 39346 microseconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "723104"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
    "tflite_model_pruned_dense = converter.convert()\n",
    "\n",
    "tflite_models_dir = pathlib.Path(\"./tflite_models/\")\n",
    "tflite_models_dir.mkdir(exist_ok=True, parents=True)\n",
    "tflite_model_file = tflite_models_dir/\"model_pruned_dense.tflite\"\n",
    "tflite_model_file.write_bytes(tflite_model_pruned_dense)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M-xayrfD9VnA"
   },
   "source": [
    "Check compressed model size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NC0h0usjX1lS",
    "outputId": "55b77379-08b4-4e1c-df7f-b13f61958649"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of compresssed baseline model: 670789.00 bytes\n",
      "Size of zipped pruned TFlite model: 245796.00 bytes\n",
      "Size of zipped pruned TFlite model only dense layers: 439992.00 bytes\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of compresssed baseline model: %.2f bytes\" % (get_gzipped_model('tflite_models/model.tflite')))\n",
    "\n",
    "print(\"Size of zipped pruned TFlite model: %.2f bytes\" % (get_gzipped_model('tflite_models/model_pruned.tflite')))\n",
    "\n",
    "print(\"Size of zipped pruned TFlite model only dense layers: %.2f bytes\" % (get_gzipped_model('tflite_models/model_pruned_dense.tflite')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DOBETrstLnZz"
   },
   "source": [
    "Check the model performance where only the dense layers are pruned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AYgw2VEHYErr",
    "outputId": "35fb5ebd-2991-4f00-9a56-84a6558cbd06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy =  0.9207\n"
     ]
    }
   ],
   "source": [
    "tflite_model_file = 'tflite_models/model_pruned_dense.tflite'          \n",
    "interpreter = tf.lite.Interpreter(model_path=tflite_model_file)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "\n",
    "pred_list = []\n",
    "for images in X_test:\n",
    "  input_data = np.array(images, dtype=np.float32)\n",
    "\n",
    "  input_data = input_data.reshape(1, input_data.shape[0], input_data.shape[1], 1)\n",
    "\n",
    "  interpreter.set_tensor(input_index, input_data)\n",
    "  interpreter.invoke()\n",
    "  prediction = interpreter.get_tensor(output_index)\n",
    "  prediction = np.argmax(prediction)\n",
    "  pred_list.append(prediction)\n",
    "\n",
    "accurate_count = 0\n",
    "for index in range(len(pred_list)):\n",
    "  if pred_list[index] == np.argmax(y_test[index]):\n",
    "      accurate_count += 1\n",
    "accuracy = accurate_count * 1.0 / len(pred_list)\n",
    "\n",
    "print('accuracy = ', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xhfHyBiP9fgI"
   },
   "source": [
    "Optimization using weight clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QlDPjjHj_Nat",
    "outputId": "c1b5ed6b-5abb-4345-84c2-114e6600f4b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " cluster_conv2d (ClusterWei  (None, 26, 26, 32)        624       \n",
      " ghts)                                                           \n",
      "                                                                 \n",
      " cluster_max_pooling2d (Clu  (None, 13, 13, 32)        0         \n",
      " sterWeights)                                                    \n",
      "                                                                 \n",
      " cluster_conv2d_1 (ClusterW  (None, 11, 11, 64)        36944     \n",
      " eights)                                                         \n",
      "                                                                 \n",
      " cluster_max_pooling2d_1 (C  (None, 5, 5, 64)          0         \n",
      " lusterWeights)                                                  \n",
      "                                                                 \n",
      " cluster_flatten (ClusterWe  (None, 1600)              0         \n",
      " ights)                                                          \n",
      "                                                                 \n",
      " cluster_dropout (ClusterWe  (None, 1600)              0         \n",
      " ights)                                                          \n",
      "                                                                 \n",
      " cluster_dense (ClusterWeig  (None, 100)               320116    \n",
      " hts)                                                            \n",
      "                                                                 \n",
      " cluster_dense_1 (ClusterWe  (None, 10)                2026      \n",
      " ights)                                                          \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 359710 (2.06 MB)\n",
      "Trainable params: 179990 (703.09 KB)\n",
      "Non-trainable params: 179720 (1.37 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "baseline_model = load_model('baseline_model.h5')\n",
    "\n",
    "cluster_weights = tfmot.clustering.keras.cluster_weights\n",
    "CentroidInitialization = tfmot.clustering.keras.CentroidInitialization\n",
    "\n",
    "clustering_params = {\n",
    "  'number_of_clusters': 16,\n",
    "  'cluster_centroids_init': CentroidInitialization.KMEANS_PLUS_PLUS\n",
    "}\n",
    "\n",
    "# Cluster a whole model\n",
    "clustered_model = cluster_weights(baseline_model, **clustering_params)\n",
    "\n",
    "# Use smaller learning rate for fine-tuning clustered model\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
    "\n",
    "clustered_model.compile(\n",
    "  loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "  optimizer=opt,\n",
    "  metrics=['accuracy'])\n",
    "\n",
    "clustered_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UjnAYLQW9n7f"
   },
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NTOrQoY6_fp0",
    "outputId": "1c81ce92-4ac2-42cf-f57f-0a64b3cf8c05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "422/422 [==============================] - 10s 21ms/step - loss: 0.1638 - accuracy: 0.9401 - val_loss: 0.1553 - val_accuracy: 0.9412\n",
      "Epoch 2/2\n",
      "422/422 [==============================] - 9s 21ms/step - loss: 0.1507 - accuracy: 0.9451 - val_loss: 0.1526 - val_accuracy: 0.9418\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f7280c06af0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fine-tune model\n",
    "clustered_model.fit(\n",
    "  X_train,\n",
    "  y_train,\n",
    "  batch_size=128,\n",
    "  epochs=2,\n",
    "  validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UceoGMIG9tEg"
   },
   "source": [
    "Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qzHdv9BTBXnt",
    "outputId": "2733f2d9-fe88-40ec-86e2-68881091c538"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp_q60ignm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp_q60ignm/assets\n",
      "2025-08-24 07:42:38.809348: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2025-08-24 07:42:38.809381: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2025-08-24 07:42:38.809607: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/tmp_q60ignm\n",
      "2025-08-24 07:42:38.810745: I tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
      "2025-08-24 07:42:38.810765: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /tmp/tmp_q60ignm\n",
      "2025-08-24 07:42:38.813531: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2025-08-24 07:42:38.837873: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /tmp/tmp_q60ignm\n",
      "2025-08-24 07:42:38.847466: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 37860 microseconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "723104"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_for_export = tfmot.clustering.keras.strip_clustering(clustered_model)\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
    "tflite_model_clustered = converter.convert()\n",
    "\n",
    "tflite_models_dir = pathlib.Path(\"./tflite_models/\")\n",
    "tflite_models_dir.mkdir(exist_ok=True, parents=True)\n",
    "tflite_model_file = tflite_models_dir/\"model_clustered.tflite\"\n",
    "tflite_model_file.write_bytes(tflite_model_clustered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "27rJKPk0-TpS"
   },
   "source": [
    "Evaluate model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d2CE1wFyB9H0",
    "outputId": "78fe00e5-9d16-4db6-9e03-450bf33bff49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.917\n"
     ]
    }
   ],
   "source": [
    "tflite_model_file = 'tflite_models/model_clustered.tflite'          \n",
    "interpreter = tf.lite.Interpreter(model_path=tflite_model_file)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "\n",
    "pred_list = []\n",
    "for images in X_test:\n",
    "  input_data = np.array(images, dtype=np.float32)\n",
    "\n",
    "  input_data = input_data.reshape(1, input_data.shape[0], input_data.shape[1], 1)\n",
    "\n",
    "  interpreter.set_tensor(input_index, input_data)\n",
    "  interpreter.invoke()\n",
    "  prediction = interpreter.get_tensor(output_index)\n",
    "  prediction = np.argmax(prediction)\n",
    "  pred_list.append(prediction)\n",
    "\n",
    "accurate_count = 0\n",
    "for index in range(len(pred_list)):\n",
    "  if pred_list[index] == np.argmax(y_test[index]):\n",
    "      accurate_count += 1\n",
    "accuracy = accurate_count * 1.0 / len(pred_list)\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TyYIw--l-Pp4"
   },
   "source": [
    "Size of compresded model after clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "laLcwu79CGko",
    "outputId": "a00a9d12-c4d2-4047-bb44-dfb94bcab83d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of zipped clustered TFlite model: 128251.00 bytes\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of zipped clustered TFlite model: %.2f bytes\" % (get_gzipped_model('tflite_models/model_clustered.tflite')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eht4Opcs-aQ6"
   },
   "source": [
    "Selective clustering on dense layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8K2CTUXrHpi8",
    "outputId": "812ce6c9-e174-4866-f3f7-d860c35b1588"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 13, 13, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 5, 5, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1600)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1600)              0         \n",
      "                                                                 \n",
      " cluster_dense (ClusterWeig  (None, 100)               320103    \n",
      " hts)                                                            \n",
      "                                                                 \n",
      " cluster_dense_1 (ClusterWe  (None, 10)                2013      \n",
      " ights)                                                          \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 340932 (1.91 MB)\n",
      "Trainable params: 179932 (702.86 KB)\n",
      "Non-trainable params: 161000 (1.23 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "baseline_model = load_model('baseline_model.h5')\n",
    "\n",
    "cluster_weights = tfmot.clustering.keras.cluster_weights\n",
    "CentroidInitialization = tfmot.clustering.keras.CentroidInitialization\n",
    "\n",
    "clustering_params = {\n",
    "  'number_of_clusters': 3,\n",
    "  'cluster_centroids_init': CentroidInitialization.KMEANS_PLUS_PLUS\n",
    "}\n",
    "\n",
    "def apply_clustering(layer):\n",
    "  if isinstance(layer, tf.keras.layers.Dense):\n",
    "    return cluster_weights(layer, **clustering_params)\n",
    "  return layer\n",
    "\n",
    "clustered_model = tf.keras.models.clone_model(\n",
    "    baseline_model,\n",
    "    clone_function=apply_clustering,\n",
    ")\n",
    "\n",
    "clustered_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZSkkuQtE-pJU"
   },
   "source": [
    "Collaborative Quantization\n",
    "\n",
    "Sparsity preserving clustering\n",
    "\n",
    "\n",
    "Firt apply weight pruning and retrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PqHDNNG2HeX_",
    "outputId": "a03a64e3-f0b0-4542-b98d-0d15176085a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " prune_low_magnitude_conv2d  (None, 26, 26, 32)        610       \n",
      "  (PruneLowMagnitude)                                            \n",
      "                                                                 \n",
      " prune_low_magnitude_max_po  (None, 13, 13, 32)        1         \n",
      " oling2d (PruneLowMagnitude                                      \n",
      " )                                                               \n",
      "                                                                 \n",
      " prune_low_magnitude_conv2d  (None, 11, 11, 64)        36930     \n",
      " _1 (PruneLowMagnitude)                                          \n",
      "                                                                 \n",
      " prune_low_magnitude_max_po  (None, 5, 5, 64)          1         \n",
      " oling2d_1 (PruneLowMagnitu                                      \n",
      " de)                                                             \n",
      "                                                                 \n",
      " prune_low_magnitude_flatte  (None, 1600)              1         \n",
      " n (PruneLowMagnitude)                                           \n",
      "                                                                 \n",
      " prune_low_magnitude_dropou  (None, 1600)              1         \n",
      " t (PruneLowMagnitude)                                           \n",
      "                                                                 \n",
      " prune_low_magnitude_dense   (None, 100)               320102    \n",
      " (PruneLowMagnitude)                                             \n",
      "                                                                 \n",
      " prune_low_magnitude_dense_  (None, 10)                2012      \n",
      " 1 (PruneLowMagnitude)                                           \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 359658 (1.37 MB)\n",
      "Trainable params: 179926 (702.84 KB)\n",
      "Non-trainable params: 179732 (702.11 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "baseline_model = load_model('baseline_model.h5')\n",
    "\n",
    "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "\n",
    "pruning_params = {\n",
    "      'pruning_schedule': tfmot.sparsity.keras.ConstantSparsity(0.5, begin_step=0, frequency=100)\n",
    "  }\n",
    "\n",
    "callbacks = [\n",
    "  tfmot.sparsity.keras.UpdatePruningStep()\n",
    "]\n",
    "\n",
    "pruned_model = prune_low_magnitude(baseline_model, **pruning_params)\n",
    "pruned_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GoYdRq9QHw1z",
    "outputId": "7aecb2f0-92f9-4840-fba0-ebb5f7e61aa1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " prune_low_magnitude_conv2d  (None, 26, 26, 32)        610       \n",
      "  (PruneLowMagnitude)                                            \n",
      "                                                                 \n",
      " prune_low_magnitude_max_po  (None, 13, 13, 32)        1         \n",
      " oling2d (PruneLowMagnitude                                      \n",
      " )                                                               \n",
      "                                                                 \n",
      " prune_low_magnitude_conv2d  (None, 11, 11, 64)        36930     \n",
      " _1 (PruneLowMagnitude)                                          \n",
      "                                                                 \n",
      " prune_low_magnitude_max_po  (None, 5, 5, 64)          1         \n",
      " oling2d_1 (PruneLowMagnitu                                      \n",
      " de)                                                             \n",
      "                                                                 \n",
      " prune_low_magnitude_flatte  (None, 1600)              1         \n",
      " n (PruneLowMagnitude)                                           \n",
      "                                                                 \n",
      " prune_low_magnitude_dropou  (None, 1600)              1         \n",
      " t (PruneLowMagnitude)                                           \n",
      "                                                                 \n",
      " prune_low_magnitude_dense   (None, 100)               320102    \n",
      " (PruneLowMagnitude)                                             \n",
      "                                                                 \n",
      " prune_low_magnitude_dense_  (None, 10)                2012      \n",
      " 1 (PruneLowMagnitude)                                           \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 359658 (1.37 MB)\n",
      "Trainable params: 179926 (702.84 KB)\n",
      "Non-trainable params: 179732 (702.11 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/keras/src/backend.py:5562: UserWarning: \"`categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "422/422 [==============================] - 10s 17ms/step - loss: 0.3649 - accuracy: 0.8612 - val_loss: 0.3129 - val_accuracy: 0.8940\n",
      "Epoch 2/3\n",
      "422/422 [==============================] - 7s 17ms/step - loss: 0.3437 - accuracy: 0.8745 - val_loss: 0.2656 - val_accuracy: 0.9092\n",
      "Epoch 3/3\n",
      "422/422 [==============================] - 7s 17ms/step - loss: 0.3060 - accuracy: 0.8885 - val_loss: 0.2428 - val_accuracy: 0.9148\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f726db3ed90>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
    "\n",
    "pruned_model.compile(\n",
    "  loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "  optimizer=opt,\n",
    "  metrics=['accuracy'])\n",
    "\n",
    "pruned_model.summary()\n",
    "\n",
    "pruned_model.fit(X_train, y_train, batch_size=128, epochs=3,validation_split=0.1, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UhTFk8Iw_5uo"
   },
   "source": [
    "Export the pruned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N_ieouEDKBhV"
   },
   "outputs": [],
   "source": [
    "stripped_pruned_model = tfmot.sparsity.keras.strip_pruning(pruned_model)\n",
    "\n",
    "stripped_pruned_model_copy = tf.keras.models.clone_model(stripped_pruned_model)\n",
    "stripped_pruned_model_copy.set_weights(stripped_pruned_model.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qr-R_7X1_8d0"
   },
   "source": [
    "Sparsity preserving clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ofr6EF2iKQgF",
    "outputId": "cf586923-e490-4a5e-f7f7-3f79b03542cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "422/422 [==============================] - 10s 20ms/step - loss: 0.1854 - accuracy: 0.9309 - val_loss: 0.1834 - val_accuracy: 0.9312\n",
      "Epoch 2/3\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.1646 - accuracy: 0.9378 - val_loss: 0.1629 - val_accuracy: 0.9390\n",
      "Epoch 3/3\n",
      "422/422 [==============================] - 8s 19ms/step - loss: 0.1510 - accuracy: 0.9436 - val_loss: 0.1725 - val_accuracy: 0.9367\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f726deaebe0>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow_model_optimization.python.core.clustering.keras.experimental import (\n",
    "    cluster,\n",
    ")\n",
    "\n",
    "cluster_weights = tfmot.clustering.keras.cluster_weights\n",
    "CentroidInitialization = tfmot.clustering.keras.CentroidInitialization.KMEANS_PLUS_PLUS\n",
    "\n",
    "cluster_weights = cluster.cluster_weights\n",
    "\n",
    "clustering_params = {\n",
    "  'number_of_clusters': 8,\n",
    "  'cluster_centroids_init': CentroidInitialization.KMEANS_PLUS_PLUS,\n",
    "  'preserve_sparsity': True\n",
    "}\n",
    "\n",
    "sparsity_clustered_model = cluster_weights(stripped_pruned_model_copy, **clustering_params)\n",
    "\n",
    "sparsity_clustered_model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "sparsity_clustered_model.fit(X_train, y_train, batch_size=128, epochs=3, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1vS-PZUgAyLl"
   },
   "source": [
    "Save with post training quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w5Vbd3kYL7aJ",
    "outputId": "3da09974-f0dd-4114-e13a-9af0d360eca6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpkkm9kw7d/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpkkm9kw7d/assets\n",
      "2025-08-24 07:46:04.690050: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2025-08-24 07:46:04.690186: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2025-08-24 07:46:04.690415: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/tmpkkm9kw7d\n",
      "2025-08-24 07:46:04.691561: I tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
      "2025-08-24 07:46:04.691582: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /tmp/tmpkkm9kw7d\n",
      "2025-08-24 07:46:04.694376: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2025-08-24 07:46:04.718802: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /tmp/tmpkkm9kw7d\n",
      "2025-08-24 07:46:04.728348: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 37935 microseconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "188672"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stripped_sparsity_clustered_model = tfmot.clustering.keras.strip_clustering(sparsity_clustered_model)\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(stripped_sparsity_clustered_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "sparsity_clustered_quant_model = converter.convert()\n",
    "\n",
    "import pathlib\n",
    "tflite_models_dir = pathlib.Path(\"./tflite_models/\")\n",
    "tflite_models_dir.mkdir(exist_ok=True, parents=True)\n",
    "tflite_model_file = tflite_models_dir/\"model_sparsity_clustered_qunat.tflite\"\n",
    "tflite_model_file.write_bytes(sparsity_clustered_quant_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pH6FYDBjA6Ra"
   },
   "source": [
    "Evaluate the model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KW5Car8KNLzR",
    "outputId": "2cda627a-1019-44bb-eae4-7ceb7dc42288"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9129\n"
     ]
    }
   ],
   "source": [
    "tflite_model_file = 'tflite_models/model_sparsity_clustered_qunat.tflite'          \n",
    "interpreter = tf.lite.Interpreter(model_path=tflite_model_file)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "\n",
    "pred_list = []\n",
    "for images in X_test:\n",
    "  input_data = np.array(images, dtype=np.float32)\n",
    "\n",
    "  input_data = input_data.reshape(1, input_data.shape[0], input_data.shape[1], 1)\n",
    "\n",
    "  interpreter.set_tensor(input_index, input_data)\n",
    "  interpreter.invoke()\n",
    "  prediction = interpreter.get_tensor(output_index)\n",
    "  prediction = np.argmax(prediction)\n",
    "  pred_list.append(prediction)\n",
    "\n",
    "accurate_count = 0\n",
    "for index in range(len(pred_list)):\n",
    "  if pred_list[index] == np.argmax(y_test[index]):\n",
    "      accurate_count += 1\n",
    "accuracy = accurate_count * 1.0 / len(pred_list)\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tE0bnHRTBCNd"
   },
   "source": [
    "Check the compressed model size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DtTZW0q3OdJv"
   },
   "outputs": [],
   "source": [
    "def get_gzipped_model(file):\n",
    "  import os\n",
    "  import zipfile\n",
    "  import tempfile\n",
    "\n",
    "  _, zipped_file = tempfile.mkstemp('.zip')\n",
    "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "    f.write(file)\n",
    "\n",
    "  return os.path.getsize(zipped_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PW43bUuiNxyg",
    "outputId": "6b8ccc1b-5ca7-4e37-a48a-504023620aaf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of zipped sparsity preserved clustered TFlite model: 59090.00 bytes\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of zipped sparsity preserved clustered TFlite model: %.2f bytes\" % (get_gzipped_model('tflite_models/model_sparsity_clustered_qunat.tflite')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
